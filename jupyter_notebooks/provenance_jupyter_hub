import json
try:
    from rspace_client.eln import eln
except:
    %pip install -q rspace-client==2.6.1

%pip install -q pickleshare
try:
    from notebook import app
except:
    %pip install -q notebook
try:
    import keyring
except:
    %pip install -q keyring
import os
import hashlib
import json
try:
    import dill
except:
    %pip install -q dill
import dill
try:
    import ipynbname
except:
    %pip install -q ipynbname
try:
    from ipylab import JupyterFrontEnd
except:
    %pip install -q ipylab
import traceback
%pip install -q lxml
from bs4 import BeautifulSoup
import nbformat
import asyncio
import getpass

try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False

if IN_COLAB == True:
    from google.colab import drive
    drive.mount('/content/drive')

RSPACE_DOC_FOR_NOTEBOOK = 'rspace_doc_for_notebook'
ATTACHMENTS_FOR_NOTEBOOK = 'data_attached_to_notebook'
GALLERY_FILE_FOR_NOTEBOOK = 'file_for_notebook'
EXECUTION_COUNT_FOR_NOTEBOOK = 'execution_count_for_notebook'
HISTORY_DATA = 'history_data'
RSPACE_DOC_URL = 'workspace/editor/structuredDocument/'
RSPACE_DOC_VERSION_URL_START = 'workspace/editor/structuredDocument/audit/view?globalId='
# Your RSpace instance goes here
RSPACE_URL = "https://researchspace2.eu.ngrok.io/"
"""
Default behaviour creates a new RSpace document when this cell is executed and attached this jupyter notebook to the
new document.

Setting RSPACE_PREEXISITING_DOCUMENT_ID to a value other than None will attach this jupyter notebook to the RSpace document
with the given ID instead of creating a new RSpace document.
"""
RSPACE_PREEXISITING_DOCUMENT_ID = None
# RSPACE_PREEXISITING_DOCUMENT_ID = 155
"""
Default behaviour writes links to this notebook into the 'first' field in a document (field '0'). Set this to a value
if a different field should be used.

If this is set to a value other than None, RSPACE_PREEXISITING_DOCUMENT_ID must be set to a value other than None.
"""
RSPACE_DOCUMENT_TARGET_FIELD_ID = None
# RSPACE_DOCUMENT_TARGET_FIELD_ID = 34
"""
    All data that will be saved to RSpace along with this notebook: select the data in the file browser and choose 'copy path'
    then paste here using a ',' comma to separate files if there is more than one.

    Example:
            attached_data_files = "spectroscopy_data.csv, data/spectroscopy_data2.csv, data/spectroscopy_data3.csv"

    If you wish to have no attached data, set this value to be "" (a pair of double quotes)

    Example:
            attached_data_files = ""
"""
attached_data_files = "spectroscopy_data.csv,data/spectroscopy_data2.csv,data/spectroscopy_data3.csv"
# attached_data_files = "/content/drive/My Drive/Colab Notebooks/spectroscopy_data3.csv,/content/drive/MyDrive/Jupyter_data/spectroscopy_data.csv,/content/drive/MyDrive/Jupyter_data/spectroscopy_data1.csv"
"""
Set this to true to manually enter a new password
"""
get_new_password = False
"""
This must be set to a the value of the PATH to the notebook (select the notebook in the file browser and choose 'copy path'),
if exceptions are thrown trying to determine the notebook name.

If this value is set server_url MUST also be set.
"""
notebook_name = None
# notebook_name = '/content/drive/My Drive/Colab Notebooks/Untitled1.ipynb'
"""
This must be set to a value if exceptions are thrown or the calculated value is incorrect when trying to determine the server url. Give the url
of the server including the port: eg http://localhost:10000 (no trailing '/')

If this value is set, notebook_name MUST also be set.
"""
server_url = None
# server_url = 'https://colab.research.google.com/drive/1dXm1-rw31_Nu-VF23OPyxxRPV19s4G5i'

"""
Set this to a value if server_url is calculated correctly except for the port (which will happen, for example
if the port is being mapped inside a docker container to an external port
"""
server_port = 10000

rspace_client = None
app = JupyterFrontEnd()

def get_server_urls():
    global server_url
    all_urls = []
    if (server_url is not None):
        all_urls.append(server_url + '/lab/tree/' + notebook_name)
    else:
        try:
            for srv in ipynbname._list_maybe_running_servers():
                srv, path = ipynbname._find_nb_path()
                if server_port is not None:
                    srv_url = srv['url']
                    # print(f"srv_url: {srv_url}")
                    # print(f"root_dir: {srv['root_dir']}")
                    # print(f"path: {str(path)}")
                    part_url = srv_url[:srv_url.rfind(':') + 1]
                    # print(f"part_url: {part_url}")
                    all_urls.append(part_url + str(server_port) + '/lab/tree/' + str(path))
                else:
                    all_urls.append(srv['url'] + 'lab/tree/' + str(path))
        except Exception:
            print(f"Error determining server urls, please manually set a value for 'server_url'")
            raise  # Code may fail if server has a password/doesnt use token auth - see ipynbname README
    return all_urls


def get_server_roots():
    """
    this will only be called if ipyname library is working correctly
    """
    all_roots = []
    try:
        if len(all_roots) == 0:
            for srv in ipynbname._list_maybe_running_servers():
                srv, path = ipynbname._find_nb_path()
                root = srv['root_dir']
                all_roots.append(root)
    except Exception:
        print(f"Error determining server roots, please manually set a value for 'server_url'")
        raise  # Code may fail if server has a password/doesnt use token auth - see ipynbname README
    return all_roots


def get_notebook_name():
    global notebook_name
    try:
        if notebook_name is not None:
            if '/' in notebook_name:
                notebook_name_alone = notebook_name[notebook_name.rfind('/') + 1:]
            else:
                notebook_name_alone = notebook_name
            return {'name': notebook_name_alone, 'root_name': notebook_name_alone[:notebook_name_alone.rfind('.')],
                    'name_path': notebook_name}
        nb_fname = ipynbname.name()
        nb_path = str(ipynbname.path())
        for srv_root in get_server_roots():
            if not srv_root.endswith("/"):
                srv_root = srv_root + "/"
            if srv_root in nb_path:
                nb_path = nb_path.replace(srv_root, '')
        # print(f"nb_path: {nb_path}")
        ext_pos = ('' + nb_path).rfind('.')
        ext = nb_path[ext_pos:]
        return {'name': nb_fname + ext, 'root_name': nb_fname, 'name_path': nb_path}
    except Exception as e:
        print(f"Error getting notebook name, please manually set a value for 'notebook_name'")
        raise


def get_password():
    """
    Retrieves password from (or saves a new password to) keyring
    """
    global get_new_password
    from keyring import get_keyring
    print("Keyring method: " + str(get_keyring()))
    try:

        # TODO - Define the service name (e.g., the notebook name the secret is for)
        service_id = "RSpaceJupyterDemoApp"
        # TODO - Define the username associated with the secret
        username = "myuser"  # use your own username

        retrieved_password = keyring.get_password(service_id, username)
        if retrieved_password is None or get_new_password:
            retrieved_password = getpass.getpass("Please enter your RSpace Api key: ")
            keyring.set_password(service_id, username, retrieved_password)
        return retrieved_password
    except Exception as e:
        print(f"Error getting password: {e}")
        return None


def get_rspace_client():
    """
    Returns rspace ELN API client
    """
    try:
        global rspace_client
        if rspace_client is None:
            retrieved_password = get_password()
            if retrieved_password is None:
                %pip install keyrings.alt
                retrieved_password = get_password()
            rspace_client = eln.ELNClient(RSPACE_URL, retrieved_password)
            print(rspace_client.get_status())
        return rspace_client
    except Exception as e:
        print(traceback.format_exc())
        print(f"Error connecting to RSpace: {e}")
        return None


def save_rspace_data(rspace_doc, attachments, gallery_file, execution_count, history_data):
    # Define the filename to save the state
    state_filename = get_notebook_name()['root_name'] + "_state.pkl"
    print(f"writing to file: {state_filename}")
    with open(state_filename, 'wb') as f:
        dill.dump({RSPACE_DOC_FOR_NOTEBOOK: rspace_doc, ATTACHMENTS_FOR_NOTEBOOK: attachments,
                   GALLERY_FILE_FOR_NOTEBOOK: gallery_file, EXECUTION_COUNT_FOR_NOTEBOOK: execution_count, HISTORY_DATA:history_data }, f)


def load_data():
    state_filename = get_notebook_name()['root_name'] + "_state.pkl"

    if os.path.exists(state_filename):
        # Load the variables from the file using dill
        with open(state_filename, 'rb') as f:
            try:
                loaded_state = dill.load(f)
            except Exception as e:
                loaded_state = {}
    else:
        loaded_state = {}
        print(f"State file '{state_filename}' not found. No variables loaded.")
    return loaded_state


async def save_notebook():
    app.commands.execute('docmanager:save')
    # 'docmanager:save' does not appear to hook into any callback invoked when the document is actually saved
    await asyncio.sleep(1)


async def reload_notebook():
    app.commands.execute('docmanager:reload')
    # 'docmanager:reload' does not appear to hook into any callback invoked when the document is actually reloaded
    await asyncio.sleep(1)

def make_metadata_cell(nb_gallery_file, attachment_files, rspace_doc, history_data):
    rspace_document_file_id =str(rspace_doc['id'])
    # new content plus new attachment data increments the document version by two
    rspace_document_version = 2 if rspace_doc['version'] == 1 else rspace_doc['version'] + 2
    rspace_document_name = rspace_doc['name']
    rspace_document_globalId = rspace_doc['globalId']+'v'+str(rspace_document_version)
    nb_gallery_file_id = nb_gallery_file['id']
    nb_gallery_file_version = int(nb_gallery_file['version'])
    # nb_gallery_file_version = 1 if nb_gallery_file_version == 1 else nb_gallery_file_version + 1
    nb_gallery_file_version = nb_gallery_file_version + 1
    nb_gallery_file_name = nb_gallery_file['name']
    meta_data_cell = nbformat.v4.new_markdown_cell()
    rspace_doc_for_markdown = f'[The RSpace Document describing this notebook, version: {rspace_document_version}]({RSPACE_URL}{RSPACE_DOC_URL}{rspace_document_file_id})'
    gallery_doc_markdown = f'[This Notebook in RSpace Gallery: {nb_gallery_file_name} version: {nb_gallery_file_version}]({RSPACE_URL}gallery/item/{nb_gallery_file_id})'
    meta_data_cell['source'] = rspace_doc_for_markdown + "<br>" + gallery_doc_markdown
    if len(attached_data_files) != 0:
        attached_data_files_list = attached_data_files.split(",")
        for attached_data in attached_data_files_list:
            attachment_file_id = attachment_files.get(attached_data, {}).get('id')
            attachment_version = attachment_files.get(attached_data, {}).get('version')
            meta_data_cell['source'] += f'<br>[Attached Data {attached_data} version: {attachment_version} ]({RSPACE_URL}gallery/item/{attachment_file_id})'
    else:
            meta_data_cell['source'] += f'<br> No Attached Data'
    for url in get_server_urls():
        meta_data_cell['source'] += f'<br>[This notebook on the jupyter server]({url})'
    new_history = f'<br>RSpace doc [<strong>{rspace_document_name}</strong> version {rspace_document_version}]({RSPACE_URL}{RSPACE_DOC_VERSION_URL_START}{rspace_document_globalId}) contains this Notebook, version {nb_gallery_file_version}, executed with: '
    if len(attached_data_files) != 0:
        for attached_data in attached_data_files.split(","):
            attachment_file_id = attachment_files.get(attached_data, {}).get('id')
            attachment_version = attachment_files.get(attached_data, {}).get('version')
            new_history += f'Data <strong>{attached_data}</strong> version: {attachment_version} '
    # print(f'history_data: {history_data}')
    history_data['text'] = new_history + history_data['text']
    meta_data_cell['source'] += f"<br> {history_data['text']}"
    meta_data_cell['metadata'] = {
        "rspace_metadata": {"documentFor": "docid", "notebook_file": "docid", "attachments": [""]}}
    return meta_data_cell

async def add_rspace_details_to_notebook_metadata(fname, notebook, nb_gallery_file, attachment_files,
                                                  rspace_doc, history_data):
    """
    We have to save meta data about a notebook before its been uploaded to the gallery.
    Therefore increment version by 1 when writing the metadata. If nb_gallery_file[id] is None
    its the initial upload to the Gallery and so do not write any meta data
    """
    if nb_gallery_file.get('id') is None:
        return
    await save_notebook()
    meta_data_cell = make_metadata_cell(nb_gallery_file, attachment_files, rspace_doc,history_data)
    replaced = False
    for i, cell in enumerate(notebook['cells']):
        if 'rspace_metadata' in cell['metadata']:
            notebook["cells"][i] = meta_data_cell
            replaced = True
    if replaced is False:
        notebook["cells"].extend([meta_data_cell])
    with open(fname, 'w', encoding='utf-8') as modified:
        nbformat.write(notebook, modified)


def get_notebook_execution_count(notebook):
    """
    return the sum of all execution counts for code cells
    note that this code cell does not contribute to the count:
    it is always saved before its execution_count gets updated
    and so the value of execution_count for this cell is always 'None'
    """
    new_executed_count = 0
    for i, cell in enumerate(notebook['cells']):
        if cell['cell_type'] == 'code':
            # print(f"cell id: {cell['id']} and execution_count {cell['execution_count']} ")
            cell_count = cell['execution_count']
            if cell_count is None:
                cell_count = 0
            new_executed_count += cell_count
            # print(f"new executed count {new_executed_count}")
    return new_executed_count


def make_content(nb_gallery_file_id, attachment_files):
    content = f"""
                <fileId={nb_gallery_file_id}>
                """
    if len(attached_data_files) != 0:
        for attachment_file in attached_data_files.split(","):
            content += f"""
            <fileId={attachment_files.get(attachment_file)['id']}>
            """
    # print(f"content is {content}")
    return content


def remove_jupyter_attachment_divs(content, nb_gallery_file_id, attachment_files):
    """
    Iterate all attachments in the document field and if any have ids matching the stored ids for this notebook
    then remove them
    """
    soup = BeautifulSoup(content, 'html.parser')
    attachment_divs = soup.find_all("div", {"class": "attachmentDiv"})
    for attachment_div in attachment_divs:
        href_tag = attachment_div.find('a')
        # print(f"href_tag{href_tag}")
        gallery_link = '/Streamfile/' + str(nb_gallery_file_id)
        if gallery_link == href_tag['href']:
            attachment_div.decompose()
            continue
        if len(attached_data_files) != 0:
            for attachment_file in attached_data_files.split(","):
                attachment_file_id = attachment_files.get(attachment_file, {}).get('id')
                attachment_link = '/Streamfile/' + str(attachment_file_id)
                if attachment_link == href_tag['href']:
                    attachment_div.decompose()
                    break
    return soup.prettify()


def upload_file_to_gallery(rspaceid, file, client):
    if rspaceid is None:
        print(f'start upload file {file} using {client}')
        data = client.upload_file(file)
    else:
        print('start update file')
        data = client.update_file(file, rspaceid)
    return data


def calc_hash(filename):
    sha256_hash = hashlib.sha256()
    with open(filename, "rb") as f:
        # Read and update hash string value in blocks of 4K
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


def upload_attached_data(attachment_files):
    client = get_rspace_client()
    if len(attached_data_files) != 0:
        attached_data_files_list = attached_data_files.split(",")
        for attached_data in attached_data_files_list:
            if attached_data:
                # make file paths to data relative to the location of this notebook
                nested_dir_pos = get_notebook_name()['name_path'].count('/')
                relative_attached_data = attached_data
                for i in range(nested_dir_pos):
                    relative_attached_data = "../" + relative_attached_data
                # print(f"relative_attached_data: {relative_attached_data}")
                with open(relative_attached_data, 'r', encoding='utf-8') as attch:
                    attachment_file_id = attachment_files.get(attached_data, {}).get('id')
                    attachment_file_hash = attachment_files.get(attached_data, {}).get('hash')
                    calc_latest_hash = calc_hash(relative_attached_data)
                    if calc_latest_hash != attachment_file_hash:
                        attachment_file_data = upload_file_to_gallery(attachment_file_id, attch, client)
                        attachment_file_data['hash'] = calc_latest_hash
                        attachment_files[attached_data] = attachment_file_data
                    else:
                        print(f"File {attached_data} not changed so no update")
    # print(f"attached files: {attachment_files}")


async def upload_notebook_to_gallery(current_notebook, notebook, nb_gallery_file, attachment_files,
                                     rspace_doc, history_data):
    """
    Metadata about the notebook is written to the notebook before it us uploaded to the Gallery (and the version incremented predictively by one).
    If the notebook has never been uploaded to the Gallery we have no stored rspace-id to write to the meta data and so we do not write any meta data.
    We do the initial upload (which creates a Gallery file with version = '1'.  Then we write meta data (incrementing the version to '2' and upload the notebook
    a second time.
    """
    await add_rspace_details_to_notebook_metadata(current_notebook, notebook, nb_gallery_file, attachment_files,
                                                  rspace_doc, history_data)
    with open(current_notebook, 'r', encoding='utf-8') as nb_file:
        client = get_rspace_client()
        nb_gallery_file = upload_file_to_gallery(nb_gallery_file.get('id'), nb_file, client)
        # print(f"gallery file for nb: {nb_gallery_file}")
    if nb_gallery_file.get('version') == 1:
        await asyncio.sleep(1)
        await add_rspace_details_to_notebook_metadata(current_notebook, notebook, nb_gallery_file, attachment_files,
                                                      rspace_doc, history_data)
        with open(current_notebook, 'r', encoding='utf-8') as nb_file:
            nb_gallery_file = upload_file_to_gallery(nb_gallery_file.get('id'), nb_file, client)
            await asyncio.sleep(1)
            # print(f"nb_gallery_file was uploaded a second time and was : {nb_gallery_file}")
    await reload_notebook()
    return nb_gallery_file

def get_field_content(rspace_doc):
    if RSPACE_DOCUMENT_TARGET_FIELD_ID is None:
        return rspace_doc['fields'][0]['content']
    else:
        for field in rspace_doc['fields']:
            if field['id'] == RSPACE_DOCUMENT_TARGET_FIELD_ID:
                return field['content']
    return None

def assert_invariants():
    if RSPACE_DOCUMENT_TARGET_FIELD_ID is not None and RSPACE_PREEXISITING_DOCUMENT_ID is None:
        raise Exception("If RSPACE_DOCUMENT_TARGET_FIELD_ID has a value RSPACE_PREEXISITING_DOCUMENT_ID must also.")

    if server_url is not None and notebook_name is None or notebook_name is not None and server_url is None:
        raise Exception("Both server_url and notebook_name must be either None or have a value")

async def sync_notebook():
    """
    Saves notebook using ipylab and then writes notebook to Rspace document as
    an attachment if the execution_count of the notebook has changed since the last time
    this cell was run. Note that the execution count of this cell does not contribute to
    the comparison - we will not write data to RSpace if only this cell has been run
    since the last time data was written to RSpace.
    Attached data is also written to RSpace if its hash_sum has changed.

    The notebook and attached data will always be written to RSpace at least once (on the first time this cell is run).
    """
    assert_invariants()
    rspace_doc = None
    attachment_filess = None
    gallery_file = None
    await save_notebook()
    get_server_urls()
    # print(f"notebook name: {get_notebook_name()}")
    current_notebook = get_notebook_name()['name'] if IN_COLAB == False else get_notebook_name()['name_path']
    with open(current_notebook, 'r') as notebook:
        notebook_node = nbformat.read(notebook, nbformat.NO_CONVERT)
    new_hash = calc_hash(current_notebook)
    # print(f" new hash {new_hash}")
    try:
        loaded_state = load_data()
        execution_count = loaded_state.get(EXECUTION_COUNT_FOR_NOTEBOOK)
        new_execution_count = get_notebook_execution_count(notebook_node)

        print(f"New execution count {new_execution_count}")
        print(f"Previous execution count {execution_count}")
        # FIXME
        # if execution_count == new_execution_count:
        #     print("No execution since last sync: no data updated in RSpace")
        #     await save_notebook()
        #     return
        client = get_rspace_client()
        rspace_doc = loaded_state.get(RSPACE_DOC_FOR_NOTEBOOK)
        attachment_files = loaded_state.get(ATTACHMENTS_FOR_NOTEBOOK, {})
        nb_gallery_file = loaded_state.get(GALLERY_FILE_FOR_NOTEBOOK, {})
        nb_gallery_file_id = nb_gallery_file.get('id')
        history_data = loaded_state.get(HISTORY_DATA,{'text':''})
        # Modified this line to get the 'name_path' which should be the actual file path
        current_notebook_info = get_notebook_name()
        current_notebook = current_notebook_info['name_path']
        attachments = None
        if rspace_doc is not None:
            print(
                f"An RSpace document with this notebook as an attachment saved previously with RSpaceID {str(rspace_doc['id'])}")
        else:
            print("No RSpace document with this notebook as an attachment saved previously in RSpace")
        upload_attached_data(attachment_files)
        if nb_gallery_file_id is not None:
            print(f"This notebook saved previously to Gallery with RSpaceID {nb_gallery_file_id}")
        else:
            print("Notebook not previously saved to RSpace Gallery")
        if rspace_doc is None and RSPACE_PREEXISITING_DOCUMENT_ID is None:
            rspace_doc = client.create_document(name="DocumentFor_" + current_notebook, tags=["Python", "API", "Jupyter"])
        rspace_document_file_id = str(rspace_doc['id']) if RSPACE_PREEXISITING_DOCUMENT_ID is None else RSPACE_PREEXISITING_DOCUMENT_ID
        rspace_doc = client.get_document(rspace_document_file_id)
        nb_gallery_file = await upload_notebook_to_gallery(current_notebook,notebook_node, nb_gallery_file,attachment_files, rspace_doc, history_data)
        # print(f"nb_gallery_file was finally: {nb_gallery_file}")
        nb_gallery_file_id = nb_gallery_file.get('id')

        previous_content = get_field_content(rspace_doc)
        previous_content = remove_jupyter_attachment_divs(previous_content, nb_gallery_file_id, attachment_files)
        new_content = previous_content + make_content(nb_gallery_file_id, attachment_files)
        if RSPACE_DOCUMENT_TARGET_FIELD_ID is not None:
            rspace_doc = client.update_document(rspace_document_file_id, tags=['Python', 'API', 'Jupyter'],
                                             fields=[{'id': RSPACE_DOCUMENT_TARGET_FIELD_ID,"content": new_content}])
        else:
            rspace_doc = client.update_document(rspace_document_file_id, tags=['Python', 'API', 'Jupyter'],
                                             fields=[{"content": new_content}])
        save_rspace_data(rspace_doc, attachment_files, nb_gallery_file, new_execution_count, history_data)
    except Exception as e:
        print(traceback.format_exc())
        print(f"Error reading notebook file: {e}")
        return None


await sync_notebook()